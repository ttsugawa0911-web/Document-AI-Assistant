import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"

import glob
import gradio as gr
import fitz
import pytesseract
from PIL import Image
import io
import cv2
import numpy as np
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_core.documents import Document
import chromadb
import logging
import time
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm

# --- 1. è¨­å®š (Configuration) ---
# â˜… DATA_FOLDERã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤
IMAGE_SAVE_FOLDER = "extracted_images/"
CHROMA_HOST = "localhost"
CHROMA_PORT = "8000"
TEXT_COLLECTION_NAME = "document_texts_v2_additive" 
IMAGE_COLLECTION_NAME = "document_images_v2_additive"
EMBEDDING_MODEL = "intfloat/multilingual-e-large"
SLIDE_CREATE_KEYWORD = "Slide Create:"
PREVIEW_CACHE_FOLDER = "preview_cache/" 

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- 2. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ­ã‚¸ãƒƒã‚¯ ---

# ... (get_chroma_client_with_retries, preprocess_image_for_ocr ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“) ...
def get_chroma_client_with_retries(host, port, retries=8, delay=5):
    last_exception = None;
    for i in range(retries):
        try:
            logging.info(f"ChromaDBã¸ã®æ¥ç¶šã‚’è©¦ã¿ã¾ã™... (è©¦è¡Œ {i+1}/{retries})"); client = chromadb.HttpClient(host=host, port=port); client.heartbeat(); logging.info("âœ… ChromaDBã¸ã®æ¥ç¶šã«æˆåŠŸã—ã¾ã—ãŸ."); return client
        except Exception as e:
            logging.warning(f"ChromaDBã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"); last_exception = e
            if i < retries - 1: logging.info(f"{delay}ç§’å¾…æ©Ÿã—ã¦ã€å†è©¦è¡Œã—ã¾ã™..."); time.sleep(delay)
    raise ConnectionError(f"ChromaDBã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆè©¦è¡Œå›æ•°: {retries}å›ï¼‰ã€‚") from last_exception

def preprocess_image_for_ocr(pil_img):
    ocv_img = np.array(pil_img); _, binary_img = cv2.threshold(ocv_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU); return Image.fromarray(binary_img)

# â˜… å¤‰æ›´ç‚¹: process_single_file ã« data_folder_path ã‚’å¼•æ•°ã¨ã—ã¦æ¸¡ã™
def process_single_file(file_path, image_save_path, data_folder_path):
    # ... (ã“ã®é–¢æ•°å†…ã®ãƒ­ã‚¸ãƒƒã‚¯è‡ªä½“ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“ãŒã€ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆã§å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒå¿…è¦ã«ãªã‚‹ãŸã‚ã€data_folder_pathã‚’æ¸¡ã™ã‚ˆã†ã«ã—ã¦ã„ã¾ã™) ...
    text_documents, image_documents, image_count = [], [], 0; base_filename = os.path.splitext(os.path.basename(file_path))[0]
    try:
        if file_path.lower().endswith('.pptx'):
            prs = Presentation(file_path)
            # ... (PPTXå‡¦ç†ã¯å¤‰æ›´ãªã—) ...
        elif file_path.lower().endswith('.pdf'):
            doc = fitz.open(file_path)
            # ... (PDFå‡¦ç†ã¯å¤‰æ›´ãªã—) ...
    except Exception as e:
        logging.error(f"Failed to process file {file_path}: {e}"); return None
    return text_documents, image_documents, image_count, os.path.basename(file_path)

# â˜… å¤‰æ›´ç‚¹: update_previews ã¨ load_document_data ã« data_folder_path ã‚’æ¸¡ã™
def load_document_data(folder_path, image_save_path, existing_sources, progress=gr.Progress()):
    # ... (tqdmã‚’ä½¿ã£ãŸé€²æ—è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—) ...
    text_documents, image_documents, image_count = [], [], 0
    pptx_files = glob.glob(os.path.join(folder_path, '**', '*.pptx'), recursive=True)
    pdf_files = glob.glob(os.path.join(folder_path, '**', '*.pdf'), recursive=True)
    all_files = pptx_files + pdf_files
    new_files = [f for f in all_files if os.path.basename(f) not in existing_sources]
    if not new_files:
        gr.Info("æ–°ã—ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return [], [], 0
    with ProcessPoolExecutor() as executor:
        futures = {executor.submit(process_single_file, f, image_save_path, folder_path): f for f in new_files}
        for future in tqdm(as_completed(futures), total=len(new_files), desc="æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­"):
            result = future.result()
            if result:
                t_docs, i_docs, i_count, fname = result
                text_documents.extend(t_docs)
                image_documents.extend(i_docs)
                image_count += i_count
    return text_documents, image_documents, image_count


# â˜… å¤‰æ›´ç‚¹: é–¢æ•°ã®å¼•æ•°ã« folder_path ã‚’è¿½åŠ 
def sync_database(folder_path, chunk_size, chunk_overlap, progress=gr.Progress(track_tqdm=True)):
    if not folder_path or not folder_path.strip():
        msg = "ã‚¨ãƒ©ãƒ¼: å‡¦ç†å¯¾è±¡ã®ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        gr.Error(msg); return msg
    if not os.path.exists(folder_path) or not os.path.isdir(folder_path):
         msg = f"ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {folder_path}\n(ã‚³ãƒ³ãƒ†ãƒŠå†…ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„)"
         gr.Error(msg); return msg
    
    # ... (DBæ¥ç¶šãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—ã€DATA_FOLDERã®ä»£ã‚ã‚Šã«folder_pathã‚’ä½¿ç”¨) ...
    if not os.path.exists(IMAGE_SAVE_FOLDER): os.makedirs(IMAGE_SAVE_FOLDER)
    if not os.path.exists(PREVIEW_CACHE_FOLDER): os.makedirs(PREVIEW_CACHE_FOLDER)
    try:
        client = get_chroma_client_with_retries(CHROMA_HOST, CHROMA_PORT); embeddings = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL, encode_kwargs={'batch_size': 32}); text_db = Chroma(client=client, collection_name=TEXT_COLLECTION_NAME, embedding_function=embeddings); image_db = Chroma(client=client, collection_name=IMAGE_COLLECTION_NAME, embedding_function=embeddings); existing_docs = text_db.get(include=["metadatas"]); existing_sources = set(meta['source'] for meta in existing_docs['metadatas'] if 'source' in meta); logging.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å­˜åœ¨ã™ã‚‹å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«: {len(existing_sources)}å€‹")
    except Exception as e: msg = f"ChromaDBã¸ã®æ¥ç¶šã¾ãŸã¯æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"; logging.error(msg); return msg
    
    text_docs, image_docs, img_count = load_document_data(folder_path, IMAGE_SAVE_FOLDER, existing_sources, progress)

    # ... (ä»¥é™ã®ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã€DBè¿½åŠ ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—) ...
    if not text_docs and not image_docs: return f"âœ… åŒæœŸå®Œäº†ã€‚æ–°ã—ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    progress(0, desc="ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ã—ã€DBã«è¿½åŠ ä¸­...")
    if text_docs:
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=int(chunk_size), chunk_overlap=int(chunk_overlap)); text_chunks = text_splitter.split_documents(text_docs); text_db.add_documents(documents=text_chunks)
    progress(0.8, desc="ç”»åƒã®æ–‡è„ˆæƒ…å ±ã‚’DBã«è¿½åŠ ä¸­...")
    if image_docs: 
        image_db.add_documents(documents=image_docs)
    total_docs_count = len(existing_sources) + len({doc.metadata['source'] for doc in text_docs}); return f"âœ… åŒæœŸå®Œäº†ã€‚{len({doc.metadata['source'] for doc in text_docs})}å€‹ã®æ–°è¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ å‡¦ç†ã—ã¾ã—ãŸã€‚(DBå†…åˆè¨ˆ: {total_docs_count}å€‹)"


# ... (initialize_systems, add_user_message ã¯å¤‰æ›´ãªã—) ...
def initialize_systems():
    try:
        client = get_chroma_client_with_retries(CHROMA_HOST, CHROMA_PORT); embeddings = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL, encode_kwargs={'batch_size': 32}); text_db = Chroma(collection_name=TEXT_COLLECTION_NAME, embedding_function=embeddings, client=client); llm = ChatOpenAI(openai_api_base="http://localhost:1234/v1", openai_api_key="not-needed", streaming=True); expert_template = "ä»¥ä¸‹ã®å‚è€ƒæƒ…å ±ã¨ã‚ãªãŸè‡ªèº«ã®çŸ¥è­˜ã‚’æŸ”è»Ÿã«çµ„ã¿åˆã‚ã›ã¦ã€è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\nå‚è€ƒæƒ…å ±:{context}\nè³ªå•:{question}\nå›ç­”:"; EXPERT_PROMPT = PromptTemplate(template=expert_template, input_variables=["context", "question"]); strict_template = "ä»¥ä¸‹ã®å‚è€ƒæƒ…å ±ã®ã¿ã‚’ä½¿ã£ã¦ã€è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚å‚è€ƒæƒ…å ±ã«ç­”ãˆãŒãªã„å ´åˆã¯ã€Œåˆ†ã‹ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚\nå‚è€ƒæƒ…å ±:{context}\nè³ªå•:{question}\nå›ç­”:"; STRICT_PROMPT = PromptTemplate(template=strict_template, input_variables=["context", "question"]); qa_chain_expert = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=text_db.as_retriever(search_kwargs={'k': 5}), return_source_documents=True, chain_type_kwargs={"prompt": EXPERT_PROMPT}); qa_chain_strict = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=text_db.as_retriever(search_kwargs={'k': 5}), return_source_documents=True, chain_type_kwargs={"prompt": STRICT_PROMPT}); image_db = Chroma(collection_name=IMAGE_COLLECTION_NAME, embedding_function=embeddings, client=client); image_retriever = image_db.as_retriever(search_kwargs={'k': 3}); systems = {"qa_chains": {"ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ": qa_chain_expert, "å³æ ¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¢ãƒ³": qa_chain_strict}, "image_retriever": image_retriever, "llm": llm}; return systems, "âœ… ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†ã€‚ChromaDBã«æ¥ç¶šæ¸ˆã¿ã§ã™ã€‚"
    except Exception as e:
        msg = f"ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}ã€‚ChromaDBã¾ãŸã¯LM Studioã¯èµ·å‹•ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ"; gr.Warning(msg); logging.error(msg); return None, msg

def add_user_message(user_message, history):
    history = history + [[user_message, None]]; return "", history, gr.update(visible=False), gr.update(value=[])

# â˜… å¤‰æ›´ç‚¹: bot_response ã¨ update_previews ã« data_folder_path ã‚’æ¸¡ã™
def bot_response(history, systems_state, answering_mode, data_folder_path):
    # ... (å‡¦ç†è‡ªä½“ã¯å¤‰æ›´ãªã—) ...
    if not systems_state:
        history[-1][1] = "ã‚¨ãƒ©ãƒ¼: ã‚·ã‚¹ãƒ†ãƒ ãŒæº–å‚™ã§ãã¦ã„ã¾ã›ã‚“ã€‚"; yield history, None; return
    user_message = history[-1][0]; history[-1][1] = ""; source_documents = []
    try:
        if answering_mode == "ãƒ–ãƒ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒŸãƒ³ã‚°":
            llm = systems_state["llm"]
            for chunk in llm.stream(user_message):
                history[-1][1] += chunk.content; yield history, None 
        else:
            qa_chain = systems_state["qa_chains"][answering_mode]; final_answer = ""
            for chunk in qa_chain.stream({'query': user_message}):
                if "result" in chunk: final_answer += chunk["result"]; history[-1][1] = final_answer; yield history, None
                if "source_documents" in chunk: source_documents = chunk["source_documents"]
    except Exception as e:
        history[-1][1] = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"; yield history, None
    yield history, source_documents

def update_previews(source_documents, data_folder_path):
    # ... (ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆæ™‚ã« data_folder_path ã‚’ä½¿ã†ã‚ˆã†ã«å¤‰æ›´) ...
    if not source_documents: return gr.update(visible=False), gr.update(value=[])
    previews = [];
    if os.path.exists(PREVIEW_CACHE_FOLDER):
        for f in glob.glob(os.path.join(PREVIEW_CACHE_FOLDER, "*")): os.remove(f)
    seen_sources = set()
    for doc in source_documents:
        source_file = doc.metadata['source']; identifier = ""; caption = ""; is_pdf = False
        if 'page_number' in doc.metadata:
            page_num = doc.metadata['page_number']; identifier = f"{source_file}_p{page_num}"; caption = f"{source_file} (p.{page_num})"; is_pdf = True
        elif 'slide_number' in doc.metadata:
            slide_num = doc.metadata['slide_number']; identifier = f"{source_file}_s{slide_num}"; caption = f"{source_file} (Slide {slide_num})"
        if identifier in seen_sources or not identifier: continue
        seen_sources.add(identifier)
        if is_pdf:
            try:
                pdf_path = os.path.join(data_folder_path, source_file) # â˜… DATA_FOLDERã®ä»£ã‚ã‚Šã«å¼•æ•°ã‚’ä½¿ç”¨
                if os.path.exists(pdf_path):
                    pdf_doc = fitz.open(pdf_path); page = pdf_doc.load_page(doc.metadata['page_number'] - 1); pix = page.get_pixmap(dpi=96); preview_img_path = os.path.join(PREVIEW_CACHE_FOLDER, f"{identifier}.png"); pix.save(preview_img_path); pdf_doc.close(); previews.append((preview_img_path, caption))
            except Exception as e: logging.error(f"PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        else:
             previews.append((None, f"ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‘\n{caption}\n----------\n{doc.page_content[:500]}..."))
    return gr.update(visible=True), gr.update(value=previews)


# â˜… å¤‰æ›´ç‚¹: UIã«ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹å…¥åŠ›æ¬„ã‚’è¿½åŠ ã—ã€ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ã‚’ä¿®æ­£
with gr.Blocks(theme=gr.themes.Soft(), title="Document AI Assistant") as demo:
    systems_state = gr.State()
    source_docs_state = gr.State()

    gr.Markdown("# ğŸ¤– Document AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
    with gr.Tabs():
        with gr.TabItem("ãƒãƒ£ãƒƒãƒˆ"):
            with gr.Row():
                with gr.Column(scale=4):
                    chatbot = gr.Chatbot(label="ãƒãƒ£ãƒƒãƒˆ", height=550, bubble_full_width=False, show_copy_button=True)
                    msg = gr.Textbox(label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸", placeholder="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...", show_label=False)
                with gr.Column(scale=1):
                    answering_mode = gr.Radio(["ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", "å³æ ¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¢ãƒ³", "ãƒ–ãƒ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒŸãƒ³ã‚°"], label="AIå›ç­”ãƒ¢ãƒ¼ãƒ‰", value="ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
                    gr.Markdown("**ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ:** DBçŸ¥è­˜+AIçŸ¥è­˜\n**å³æ ¼:** DBçŸ¥è­˜ã®ã¿\n**ãƒ–ãƒ¬ã‚¤ãƒ³:** AIçŸ¥è­˜ã®ã¿")
            with gr.Accordion("å‚ç…§å…ƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", open=True, visible=False) as preview_accordion:
                source_gallery = gr.Gallery(label="å‚ç…§ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒšãƒ¼ã‚¸", show_label=False, elem_id="gallery", columns=4, height="auto")

        with gr.TabItem("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†"):
            with gr.Column():
                gr.Markdown("### âš™ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š")
                
                # â˜… ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹å…¥åŠ›ç”¨ã®Textboxã‚’è¿½åŠ 
                folder_path_input = gr.Textbox(
                    label="å‡¦ç†å¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹",
                    placeholder="/host-docs/MedicalPapers ãªã©ã€ã‚³ãƒ³ãƒ†ãƒŠå†…ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›",
                    info="docker-compose.ymlã§è¨­å®šã—ãŸãƒœãƒªãƒ¥ãƒ¼ãƒ å†…ã®ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™ã€‚"
                )

                with gr.Accordion("ãƒãƒ£ãƒ³ã‚¯è¨­å®šï¼ˆä¸Šç´šè€…å‘ã‘ï¼‰", open=False):
                    chunk_size_input = gr.Number(label="Chunk Size", value=1000, step=50)
                    chunk_overlap_input = gr.Number(label="Chunk Overlap", value=150, step=10)
                
                sync_db_btn = gr.Button("Sync Database", variant="primary")
                status_output = gr.Textbox(label="ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", interactive=False, lines=5)

    # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ã‚’ä¿®æ­£
    msg.submit(
        add_user_message, 
        [msg, chatbot], 
        [msg, chatbot, preview_accordion, source_gallery]
    ).then(
        bot_response, 
        [chatbot, systems_state, answering_mode, folder_path_input], # folder_path_inputã‚’è¿½åŠ 
        [chatbot, source_docs_state]
    ).then(
        update_previews,
        [source_docs_state, folder_path_input], # folder_path_inputã‚’è¿½åŠ 
        [preview_accordion, source_gallery]
    )
    
    sync_db_btn.click(
        fn=sync_database, 
        inputs=[folder_path_input, chunk_size_input, chunk_overlap_input], # folder_path_inputã‚’è¿½åŠ 
        outputs=status_output
    ).then(fn=initialize_systems, outputs=[systems_state, status_output])
    
    demo.load(fn=initialize_systems, outputs=[systems_state, status_output])

if __name__ == "__main__":
    if not os.path.exists(PREVIEW_CACHE_FOLDER):
        os.makedirs(PREVIEW_CACHE_FOLDER)
    demo.queue()
    demo.launch()